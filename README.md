# WHEN AI LEARNS THE MUSIC
### _Powered by The Deep Sleeping Crew (Group6)_

<img src="https://miro.medium.com/max/810/1*kRRiGuDIoRF9OAKBRA6gmg.jpeg"> 
 
## Highlights
pending

## 1. Introduction
> Sounds are all around us, from birds chirping and waves lapping against a coastline to cars honking in traffic. But sometimes sounds are put together in purposeful ways to create a specific atmosphere or to express ideas or emotions. Such organized sounds are called **`"music"`**.

Song is a collection of coordinated sounds which have a lot of elements including quantity in terms of engineering, art mixture, even its maker such as artist, composer both can effect to many version of the song.

However, the indicator which is the best representative for identification is the **`"song name"`**. Even if that song may be sung by a new artist under different conditions. A human can sense and separate the song's identity and communicate via song name

The one of big pain points we commonly face is hearing just only one part of the song and falling in love with it but don't know its name

Our team would like to solve this problem with AI by applying **`Sequential models`** such as **`RNN`**, **`LSTM`**, and **`GRU`** for **`multi-classification`**

Input: Feature of the song (**`Amplitude`** and **`Frequency Domain`**)

Output: **`Song Name`**

## 2. Dataset

### Data source
mp3 file downloaded from YouTube with 2 versions, the **`original`** and **`cover`** version. We use the song covered by another artist to be the **`test dataset`**
